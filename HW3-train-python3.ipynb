{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "    \n",
    "    with open(os.path.join(data_dir, 'validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "            \n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_silence_':\n",
    "                continue\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "            \n",
    "            label_id = name2id[label]\n",
    "            \n",
    "            sample = (label, label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "    columns_list = ['label', 'label_id', 'user_id', 'wav_file']\n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = load_data('./data/')\n",
    "train_df.head()\n",
    "train_df.label.value_counts()\n",
    "silence_files = train_df[train_df.label == 'silence']\n",
    "train_df = train_df[train_df.label != 'silence']\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def read_wav_file(fname):\n",
    "    _, wav = wavfile.read(fname)\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav\n",
    "\n",
    "silence_data = np.concatenate([read_wav_file(x) for x in silence_files.wav_file.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "\n",
    "def process_wav_file(fname):\n",
    "    wav = read_wav_file(fname)\n",
    "    \n",
    "    L = 16000\n",
    "    \n",
    "    if len(wav) > L:\n",
    "        i = np.random.randint(0, len(wav) - L) # 這是是減L不是len\n",
    "        wav = wav[i: (i+L)]\n",
    "    elif len(wav) < L:\n",
    "        rem_len = L - len(wav)\n",
    "        i = np.random.randint(0, len(silence_data) - rem_len)\n",
    "        silence_part = silence_data[i: (i+L)]\n",
    "        j = np.random.randint(0, rem_len)\n",
    "        silence_part_left = silence_part[0: j]\n",
    "        silence_part_right = silence_part[j: rem_len]\n",
    "        wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "    \n",
    "    specgram = stft(wav, 16000, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "    phase = np.angle(specgram[2]) / np.pi\n",
    "    amp = np.log1p(np.abs(specgram[2]))\n",
    "    \n",
    "    return np.stack([phase, amp], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_train = train_df.groupby('label_id').apply(lambda x: x.sample(n = 100))\n",
    "        shuffled_ids = random.sample(range(this_train.shape[0]), this_train.shape[0])\n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            i_train_batch = shuffled_ids[start: end]\n",
    "            for i in i_train_batch:\n",
    "                x_batch.append(process_wav_file(this_train.wav_file.values[i]))\n",
    "                y_batch.append(this_train.label_id.values[i])\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = np_utils.to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch\n",
    "            \n",
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start: end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(process_wav_file(valid_df.wav_file.values[i]))\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = np_utils.to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 257, 98, 2)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 257, 98, 2)   8           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 255, 96, 16)  304         batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 255, 96, 16)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 255, 96, 16)  64          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 127, 48, 16)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 125, 46, 32)  4640        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 125, 46, 32)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 125, 46, 32)  128         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 62, 23, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 60, 21, 64)   18496       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 60, 21, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 60, 21, 64)   256         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 30, 10, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 8, 128)   73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 28, 8, 128)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 8, 128)   512         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 14, 4, 128)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 12, 2, 256)   295168      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 12, 2, 256)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 12, 2, 256)   1024        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 6, 1, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 6, 1, 64)     16448       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 64)           0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12)           780         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 419,940\n",
      "Trainable params: 418,944\n",
      "Non-trainable params: 996\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_in = Input(shape = (257, 98, 2))\n",
    "x = BatchNormalization()(x_in)\n",
    "for i in range(5):\n",
    "    x = Conv2D(16*(2 ** i), (3,3))(x)\n",
    "    x = Activation('elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "x = Conv2D(64, (1,1))(x)\n",
    "x_branch_1 = GlobalAveragePooling2D()(x)\n",
    "x_branch_2 = GlobalMaxPool2D()(x)\n",
    "x = concatenate([x_branch_1, x_branch_2])\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'sigmoid')(x)\n",
    "model = Model(inputs = x_in, outputs = x)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.6821 - acc: 0.7748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 123s 154ms/step - loss: 0.6819 - acc: 0.7748 - val_loss: 0.8541 - val_acc: 0.7224\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 121s 152ms/step - loss: 0.3940 - acc: 0.8769 - val_loss: 0.6259 - val_acc: 0.7967\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 122s 152ms/step - loss: 0.2969 - acc: 0.9089 - val_loss: 0.5616 - val_acc: 0.8492\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 121s 151ms/step - loss: 0.2397 - acc: 0.9273 - val_loss: 0.6210 - val_acc: 0.8431\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 121s 151ms/step - loss: 0.2162 - acc: 0.9365 - val_loss: 0.5394 - val_acc: 0.8660\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 121s 152ms/step - loss: 0.1786 - acc: 0.9473 - val_loss: 0.4447 - val_acc: 0.8869\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 121s 152ms/step - loss: 0.1680 - acc: 0.9509 - val_loss: 0.7236 - val_acc: 0.8302\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 122s 153ms/step - loss: 0.1539 - acc: 0.9563 - val_loss: 0.7073 - val_acc: 0.8764\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 121s 152ms/step - loss: 0.1409 - acc: 0.9602 - val_loss: 0.6033 - val_acc: 0.9031\n",
      "Epoch 10/20\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9625\n",
      "Epoch 00010: reducing learning rate to 0.00010000000474974513.\n",
      "800/800 [==============================] - 122s 153ms/step - loss: 0.1425 - acc: 0.9625 - val_loss: 0.6525 - val_acc: 0.8848\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 122s 152ms/step - loss: 0.0756 - acc: 0.9792 - val_loss: 0.4121 - val_acc: 0.9319\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 121s 152ms/step - loss: 0.0492 - acc: 0.9874 - val_loss: 0.4145 - val_acc: 0.9325\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 122s 152ms/step - loss: 0.0379 - acc: 0.9898 - val_loss: 0.4268 - val_acc: 0.9344\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 122s 152ms/step - loss: 0.0381 - acc: 0.9906 - val_loss: 0.4291 - val_acc: 0.9358\n",
      "Epoch 15/20\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9919\n",
      "Epoch 00015: reducing learning rate to 1.0000000474974514e-05.\n",
      "800/800 [==============================] - 122s 152ms/step - loss: 0.0330 - acc: 0.9919 - val_loss: 0.4276 - val_acc: 0.9382\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 121s 151ms/step - loss: 0.0270 - acc: 0.9930 - val_loss: 0.4255 - val_acc: 0.9383\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import h5py as h5py\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', \n",
    "                          patience = 5, \n",
    "                          verbose = 1,\n",
    "                          min_delta = 0.01, \n",
    "                          mode = 'min'), \n",
    "            ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                          factor = 0.1, \n",
    "                          patience = 3, \n",
    "                          verbose = 1, \n",
    "                          epsilon = 0.01,  \n",
    "                          mode = 'min'), \n",
    "            ModelCheckpoint(monitor = 'val_loss', \n",
    "                          filepath = 'weights/starter.hdf5', \n",
    "                          save_best_only = True, \n",
    "                          save_weights_only = True, \n",
    "                          mode = 'min'),\n",
    "            TensorBoard(log_dir='./logs', # 這是紅衣說可以拿來跑LOG的\n",
    "                          histogram_freq=0, \n",
    "                          batch_size=32, \n",
    "                          write_graph=True, \n",
    "                          write_grads=False, \n",
    "                          write_images=False, \n",
    "                          embeddings_freq=0, \n",
    "                          embeddings_layer_names=None, \n",
    "                          embeddings_metadata=None)]\n",
    "# TQDMNotebookCallback()\n",
    "\n",
    "epochSize = 20 #50\n",
    "steps_per_epoch = 800 #344\n",
    "history = model.fit_generator(generator = train_generator(64), \n",
    "                             steps_per_epoch = steps_per_epoch, \n",
    "                             epochs = epochSize,\n",
    "                             verbose = 1, \n",
    "                             callbacks = callbacks,\n",
    "                             validation_data = valid_generator(64), \n",
    "                             validation_steps = int(np.ceil(valid_df.shape[0]/64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#model.load_weights('./weights/starter.hdf5')\n",
    "now = datetime.datetime.now()\n",
    "saveFileName = str(epochSize)+'_'+str(steps_per_epoch)+'.h5' \n",
    "model.save('model/'+saveFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
