{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "def process_wav_file(fname):\n",
    "    wav = read_wav_file(fname)\n",
    "    \n",
    "    L = 16000\n",
    "    \n",
    "    if len(wav) > L:\n",
    "        i = np.random.randint(0, len(wav) - L) # 這是錯誤\n",
    "        wav = wav[i: (i+L)]\n",
    "    elif len(wav) < L:\n",
    "        rem_len = L - len(wav)\n",
    "        i = np.random.randint(0, len(silence_data) - rem_len)\n",
    "        silence_part = silence_data[i: (i+L)]\n",
    "        j = np.random.randint(0, rem_len)\n",
    "        silence_part_left = silence_part[0: j]\n",
    "        silence_part_right = silence_part[j: rem_len]\n",
    "        wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "    \n",
    "    specgram = stft(wav, 16000, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "    phase = np.angle(specgram[2]) / np.pi\n",
    "    amp = np.log1p(np.abs(specgram[2]))\n",
    "    \n",
    "    return np.stack([phase, amp], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)\n",
    "\n",
    "def load_data(data_dir):\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "    \n",
    "    with open(os.path.join(data_dir, 'validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "            \n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_silence_':\n",
    "                continue\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "            \n",
    "            label_id = name2id[label]\n",
    "            \n",
    "            sample = (label, label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "    columns_list = ['label', 'label_id', 'user_id', 'wav_file']\n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = load_data('./data/')\n",
    "train_df.head()\n",
    "train_df.label.value_counts()\n",
    "silence_files = train_df[train_df.label == 'silence']\n",
    "train_df = train_df[train_df.label != 'silence']\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def read_wav_file(fname):\n",
    "    _, wav = wavfile.read(fname)\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "    return wav\n",
    "\n",
    "silence_data = np.concatenate([read_wav_file(x) for x in silence_files.wav_file.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/*wav'))\n",
    "def test_generator(test_batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(test_paths), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(test_paths))\n",
    "            this_paths = test_paths[start: end]\n",
    "            for x in this_paths:\n",
    "                x_batch.append(process_wav_file(x))\n",
    "            x_batch = np.array(x_batch)\n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'model/20_800.h5'\n",
    "model = load_model(filePath)\n",
    "\n",
    "predictions = model.predict_generator(test_generator(64), int(np.ceil(len(test_paths)/64)))\n",
    "classes = np.argmax(predictions, axis = 1)\n",
    "\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label\n",
    "    \n",
    "with open('starter_submission.csv', 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
